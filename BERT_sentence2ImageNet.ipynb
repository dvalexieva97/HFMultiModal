{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "BERT_sentence2ImageNet",
      "provenance": [],
      "collapsed_sections": [
        "-8kEDRvShcU5",
        "aRp4O7D295d_"
      ]
    },
    "kernelspec": {
      "display_name": "Environment (conda_pytorch_latest_p37)",
      "language": "python",
      "name": "conda_pytorch_latest_p37"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RX_ZDhicpHkV"
      },
      "source": [
        "# 1. Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVTFzoK7oWbC",
        "outputId": "c0492462-bcb7-4511-bff9-4f6b3d24a48b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install tensorflow\n",
        "!pip install torch\n",
        "!pip install transformers\n",
        "!pip install seaborn"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.0)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.25.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.44.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.2.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.53)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (0.11.2)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.4.1)\n",
            "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.7/dist-packages (from seaborn) (3.2.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (1.4.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (3.0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=2.2->seaborn) (4.2.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->seaborn) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=2.2->seaborn) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, BertConfig"
      ],
      "metadata": {
        "id": "Y4EFfxnOE-ys"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEfSbAA4QHas",
        "outputId": "1e1a953d-f1dd-4b2e-9e27-74b8ebe8f238"
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "if device_name == '/device:GPU:0':\n",
        "    print(f'Found GPU at: {device_name}')\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgcSiSK9pKCH"
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3t4oerkSaBR",
        "outputId": "4caddfbc-87c9-44b6-bea7-abcf6fa1087e"
      },
      "source": [
        "if torch.cuda.is_available():    \n",
        "\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('GPU to be used:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "GPU to be used: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUhYfQCuEOR8",
        "outputId": "c69b35c1-c7ee-4112-f2de-65d17b894406"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon May  9 00:29:36 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   74C    P0    32W /  70W |   4340MiB / 15109MiB |     13%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbESEDvqvcuk"
      },
      "source": [
        "# Helper function to save our model:\n",
        "\n",
        "import os\n",
        "output_dir = 'model/bert'\n",
        "\n",
        "def save_model(output_dir):\n",
        "\n",
        "  # Create output directory if needed\n",
        "  if not os.path.exists(output_dir):\n",
        "      os.makedirs(output_dir)\n",
        "  print(\"Saving model to %s\" % output_dir)\n",
        "  # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "  # They can then be reloaded using `from_pretrained()`\n",
        "  model_to_save = model.modules if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "  model_to_save.save_pretrained(output_dir, save_config=True)\n",
        "  tokenizer.save_pretrained(output_dir)\n",
        "  print(\"model saved\")"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JrUHXms16cn"
      },
      "source": [
        "## 2. Load data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "labels_tensor.bin and tokens_tensor.bin were generated "
      ],
      "metadata": {
        "id": "kRuQWsmNGNqq"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMtmPMkBzrvs",
        "outputId": "bb7c4f52-eb4a-4c0a-d75f-275c7c59f674"
      },
      "source": [
        "labels_tensor = torch.load('labels_tensor.bin')\n",
        "tokens_tensor = torch.load('tokens_tensor.bin')\n",
        "print(\"Loaded tensor data \\n\" \n",
        "      f\"Total datapoints: {len(labels_tensor)}\")"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded tensor data \n",
            "Total datapoints: 3940\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8kEDRvShcU5"
      },
      "source": [
        "## 3. Load BERT for sequence classification"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_LABELS = 1000\n",
        "BATCH_SIZE = 32"
      ],
      "metadata": {
        "id": "9p4AZ-hHEj21"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z474sSC6oe7A",
        "outputId": "0302c22f-c0b3-40dc-b473-34d0ce0584d7"
      },
      "source": [
        "print('Loading BERT model and tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased',\n",
        "                                                           num_labels = NUM_LABELS, \n",
        "                                                           output_attentions = True, \n",
        "                                                           output_hidden_states = True\n",
        "                                                           )\n",
        "model.cuda()\n",
        "print(\"Loaded\")"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT model and tokenizer...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRp4O7D295d_"
      },
      "source": [
        "## 4. Training & Validation Split\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEgLpFVlo1Z-",
        "outputId": "eb04cbd2-0def-41ff-ee9b-58e9b36e6c98"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset:\n",
        "dataset = TensorDataset(tokens_tensor, labels_tensor)\n",
        "\n",
        "# Create a 95-5 train-validation split:\n",
        "\n",
        "train_size = int(0.95 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples:\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3,743 training samples\n",
            "  197 validation samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dD9i6Z2pG-sN"
      },
      "source": [
        "We'll also create an iterator for our dataset using the torch DataLoader class. This helps save on memory during training because, unlike a for loop, with an iterator the entire dataset does not need to be loaded into memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGUqOCtgqGhP"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = BATCH_SIZE # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = BATCH_SIZE # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bwa6Rts-02-"
      },
      "source": [
        "# 4. Model training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRWT-D4U_Pvx"
      },
      "source": [
        "## 4.1. Optimizer & Learning Rate Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p0upAhhRiIx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe0bd880-0472-4da1-8470-89e0fb660ca4"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "epochs = 30 \n",
        "batch_size = BATCH_SIZE\n",
        "\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n",
        "\n",
        "# Learning rate scheduler:\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpt6tR83keZD"
      },
      "source": [
        "# Helper function to format elapsed times \n",
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "metadata": {
        "id": "rNLFnHX4N7Q8"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqfmWwUR_Sox"
      },
      "source": [
        "## 4.2. Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6J-FYdx6nFE_",
        "outputId": "9f491dd4-9fc5-4d55-c59b-60a1aab8c0ae"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "        \n",
        "        if step % 5000 == 0 and not step == 0:\n",
        "            \n",
        "            save_model(output_dir + str(step) + '/')\n",
        "\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        # b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[1].to(device)\n",
        "\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "        outputs = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                            #  attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        # b_input_mask = batch[1].to(device) # note masking not used\n",
        "        b_labels = batch[1].to(device)\n",
        "        \n",
        "        with torch.no_grad():        \n",
        "\n",
        "            outputs = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                  #  attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "    if epoch_i % 5 == 0:\n",
        "      save_model(output_dir + '_epoch_' + str(epoch_i+1))\n",
        "\n",
        "\n",
        "save_model(output_dir + 'final')\n",
        "\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    117.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    117.    Elapsed: 0:00:16.\n",
            "\n",
            "  Average training loss: 6.85\n",
            "  Training epcoh took: 0:00:24\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.00\n",
            "  Validation Loss: 6.70\n",
            "  Validation took: 0:00:00\n",
            "Saving model to model/bert_epoch_1\n",
            "model saved\n",
            "\n",
            "======== Epoch 2 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    117.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    117.    Elapsed: 0:00:16.\n",
            "\n",
            "  Average training loss: 6.58\n",
            "  Training epcoh took: 0:00:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.00\n",
            "  Validation Loss: 6.52\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 3 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    117.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    117.    Elapsed: 0:00:16.\n",
            "\n",
            "  Average training loss: 6.44\n",
            "  Training epcoh took: 0:00:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.00\n",
            "  Validation Loss: 6.46\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 4 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    117.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    117.    Elapsed: 0:00:16.\n",
            "\n",
            "  Average training loss: 6.37\n",
            "  Training epcoh took: 0:00:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.00\n",
            "  Validation Loss: 6.42\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 5 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    117.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    117.    Elapsed: 0:00:16.\n",
            "\n",
            "  Average training loss: 6.26\n",
            "  Training epcoh took: 0:00:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.01\n",
            "  Validation Loss: 6.23\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 6 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    117.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    117.    Elapsed: 0:00:16.\n",
            "\n",
            "  Average training loss: 6.02\n",
            "  Training epcoh took: 0:00:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.04\n",
            "  Validation Loss: 5.97\n",
            "  Validation took: 0:00:00\n",
            "Saving model to model/bert_epoch_6\n",
            "model saved\n",
            "\n",
            "======== Epoch 7 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    117.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    117.    Elapsed: 0:00:16.\n",
            "\n",
            "  Average training loss: 5.74\n",
            "  Training epcoh took: 0:00:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.19\n",
            "  Validation Loss: 5.66\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 8 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    117.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    117.    Elapsed: 0:00:16.\n",
            "\n",
            "  Average training loss: 5.46\n",
            "  Training epcoh took: 0:00:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.29\n",
            "  Validation Loss: 5.39\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 9 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    117.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    117.    Elapsed: 0:00:16.\n",
            "\n",
            "  Average training loss: 5.19\n",
            "  Training epcoh took: 0:00:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.37\n",
            "  Validation Loss: 5.16\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 10 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    117.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    117.    Elapsed: 0:00:16.\n",
            "\n",
            "  Average training loss: 4.93\n",
            "  Training epcoh took: 0:00:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.42\n",
            "  Validation Loss: 4.93\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 11 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    117.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    117.    Elapsed: 0:00:16.\n",
            "\n",
            "  Average training loss: 4.70\n",
            "  Training epcoh took: 0:00:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.47\n",
            "  Validation Loss: 4.71\n",
            "  Validation took: 0:00:00\n",
            "Saving model to model/bert_epoch_11\n",
            "model saved\n",
            "\n",
            "======== Epoch 12 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    117.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    117.    Elapsed: 0:00:16.\n",
            "\n",
            "  Average training loss: 4.48\n",
            "  Training epcoh took: 0:00:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.59\n",
            "  Validation Loss: 4.51\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 13 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    117.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    117.    Elapsed: 0:00:16.\n",
            "\n",
            "  Average training loss: 4.28\n",
            "  Training epcoh took: 0:00:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.64\n",
            "  Validation Loss: 4.32\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 14 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    117.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    117.    Elapsed: 0:00:16.\n",
            "\n",
            "  Average training loss: 4.09\n",
            "  Training epcoh took: 0:00:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.68\n",
            "  Validation Loss: 4.16\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 15 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    117.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    117.    Elapsed: 0:00:16.\n",
            "\n",
            "  Average training loss: 3.91\n",
            "  Training epcoh took: 0:00:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.73\n",
            "  Validation Loss: 3.99\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 16 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    117.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    117.    Elapsed: 0:00:16.\n",
            "\n",
            "  Average training loss: 3.75\n",
            "  Training epcoh took: 0:00:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 3.84\n",
            "  Validation took: 0:00:00\n",
            "Saving model to model/bert_epoch_16\n",
            "model saved\n",
            "\n",
            "======== Epoch 17 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    117.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    117.    Elapsed: 0:00:16.\n",
            "\n",
            "  Average training loss: 3.60\n",
            "  Training epcoh took: 0:00:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.79\n",
            "  Validation Loss: 3.71\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 18 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    117.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    117.    Elapsed: 0:00:16.\n",
            "\n",
            "  Average training loss: 3.47\n",
            "  Training epcoh took: 0:00:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.81\n",
            "  Validation Loss: 3.60\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 19 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    117.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    117.    Elapsed: 0:00:16.\n",
            "\n",
            "  Average training loss: 3.34\n",
            "  Training epcoh took: 0:00:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 3.49\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 20 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    117.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    117.    Elapsed: 0:00:16.\n",
            "\n",
            "  Average training loss: 3.23\n",
            "  Training epcoh took: 0:00:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "  Validation Loss: 3.38\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 21 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    117.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    117.    Elapsed: 0:00:16.\n",
            "\n",
            "  Average training loss: 3.13\n",
            "  Training epcoh took: 0:00:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "  Validation Loss: 3.29\n",
            "  Validation took: 0:00:00\n",
            "Saving model to model/bert_epoch_21\n",
            "model saved\n",
            "\n",
            "======== Epoch 22 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    117.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    117.    Elapsed: 0:00:16.\n",
            "\n",
            "  Average training loss: 3.04\n",
            "  Training epcoh took: 0:00:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "  Validation Loss: 3.22\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 23 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    117.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    117.    Elapsed: 0:00:16.\n",
            "\n",
            "  Average training loss: 2.95\n",
            "  Training epcoh took: 0:00:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "  Validation Loss: 3.13\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 24 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    117.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    117.    Elapsed: 0:00:16.\n",
            "\n",
            "  Average training loss: 2.88\n",
            "  Training epcoh took: 0:00:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 3.06\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 25 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    117.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    117.    Elapsed: 0:00:16.\n",
            "\n",
            "  Average training loss: 2.82\n",
            "  Training epcoh took: 0:00:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "  Validation Loss: 3.01\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 26 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    117.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    117.    Elapsed: 0:00:16.\n",
            "\n",
            "  Average training loss: 2.78\n",
            "  Training epcoh took: 0:00:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 2.97\n",
            "  Validation took: 0:00:00\n",
            "Saving model to model/bert_epoch_26\n",
            "model saved\n",
            "\n",
            "======== Epoch 27 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    117.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    117.    Elapsed: 0:00:16.\n",
            "\n",
            "  Average training loss: 2.74\n",
            "  Training epcoh took: 0:00:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.89\n",
            "  Validation Loss: 2.94\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 28 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    117.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    117.    Elapsed: 0:00:16.\n",
            "\n",
            "  Average training loss: 2.70\n",
            "  Training epcoh took: 0:00:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.89\n",
            "  Validation Loss: 2.91\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 29 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    117.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    117.    Elapsed: 0:00:16.\n",
            "\n",
            "  Average training loss: 2.69\n",
            "  Training epcoh took: 0:00:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.89\n",
            "  Validation Loss: 2.90\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 30 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    117.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    117.    Elapsed: 0:00:16.\n",
            "\n",
            "  Average training loss: 2.67\n",
            "  Training epcoh took: 0:00:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.89\n",
            "  Validation Loss: 2.89\n",
            "  Validation took: 0:00:00\n",
            "Saving model to model/bertfinal\n",
            "model saved\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:11:51 (h:mm:ss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQTvJ1vRP7u4"
      },
      "source": [
        "# 5. Training Process - Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O_NbXFGMukX",
        "outputId": "78915cf8-0f1e-4b58-ccc7-6bfbeb4ae070",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.set_option('precision', 2)\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "df_stats"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               6.85         6.70       4.46e-03       0:00:24         0:00:00\n",
              "2               6.58         6.52       4.46e-03       0:00:23         0:00:00\n",
              "3               6.44         6.46       4.46e-03       0:00:23         0:00:00\n",
              "4               6.37         6.42       4.46e-03       0:00:23         0:00:00\n",
              "5               6.26         6.23       1.34e-02       0:00:23         0:00:00\n",
              "6               6.02         5.97       4.46e-02       0:00:23         0:00:00\n",
              "7               5.74         5.66       1.91e-01       0:00:23         0:00:00\n",
              "8               5.46         5.39       2.87e-01       0:00:23         0:00:00\n",
              "9               5.19         5.16       3.71e-01       0:00:23         0:00:00\n",
              "10              4.93         4.93       4.25e-01       0:00:23         0:00:00\n",
              "11              4.70         4.71       4.74e-01       0:00:23         0:00:00\n",
              "12              4.48         4.51       5.92e-01       0:00:23         0:00:00\n",
              "13              4.28         4.32       6.37e-01       0:00:23         0:00:00\n",
              "14              4.09         4.16       6.77e-01       0:00:23         0:00:00\n",
              "15              3.91         3.99       7.26e-01       0:00:23         0:00:00\n",
              "16              3.75         3.84       7.81e-01       0:00:23         0:00:00\n",
              "17              3.60         3.71       7.86e-01       0:00:23         0:00:00\n",
              "18              3.47         3.60       8.08e-01       0:00:23         0:00:00\n",
              "19              3.34         3.49       8.39e-01       0:00:23         0:00:00\n",
              "20              3.23         3.38       8.48e-01       0:00:23         0:00:00\n",
              "21              3.13         3.29       8.53e-01       0:00:23         0:00:00\n",
              "22              3.04         3.22       8.62e-01       0:00:23         0:00:00\n",
              "23              2.95         3.13       8.66e-01       0:00:23         0:00:00\n",
              "24              2.88         3.06       8.79e-01       0:00:23         0:00:00\n",
              "25              2.82         3.01       8.71e-01       0:00:23         0:00:00\n",
              "26              2.78         2.97       8.79e-01       0:00:23         0:00:00\n",
              "27              2.74         2.94       8.88e-01       0:00:23         0:00:00\n",
              "28              2.70         2.91       8.93e-01       0:00:23         0:00:00\n",
              "29              2.69         2.90       8.88e-01       0:00:23         0:00:00\n",
              "30              2.67         2.89       8.93e-01       0:00:23         0:00:00"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3ae90bd5-04ed-4156-8a50-43061d664900\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.85</td>\n",
              "      <td>6.70</td>\n",
              "      <td>4.46e-03</td>\n",
              "      <td>0:00:24</td>\n",
              "      <td>0:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6.58</td>\n",
              "      <td>6.52</td>\n",
              "      <td>4.46e-03</td>\n",
              "      <td>0:00:23</td>\n",
              "      <td>0:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6.44</td>\n",
              "      <td>6.46</td>\n",
              "      <td>4.46e-03</td>\n",
              "      <td>0:00:23</td>\n",
              "      <td>0:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6.37</td>\n",
              "      <td>6.42</td>\n",
              "      <td>4.46e-03</td>\n",
              "      <td>0:00:23</td>\n",
              "      <td>0:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6.26</td>\n",
              "      <td>6.23</td>\n",
              "      <td>1.34e-02</td>\n",
              "      <td>0:00:23</td>\n",
              "      <td>0:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6.02</td>\n",
              "      <td>5.97</td>\n",
              "      <td>4.46e-02</td>\n",
              "      <td>0:00:23</td>\n",
              "      <td>0:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>5.74</td>\n",
              "      <td>5.66</td>\n",
              "      <td>1.91e-01</td>\n",
              "      <td>0:00:23</td>\n",
              "      <td>0:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>5.46</td>\n",
              "      <td>5.39</td>\n",
              "      <td>2.87e-01</td>\n",
              "      <td>0:00:23</td>\n",
              "      <td>0:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>5.19</td>\n",
              "      <td>5.16</td>\n",
              "      <td>3.71e-01</td>\n",
              "      <td>0:00:23</td>\n",
              "      <td>0:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>4.93</td>\n",
              "      <td>4.93</td>\n",
              "      <td>4.25e-01</td>\n",
              "      <td>0:00:23</td>\n",
              "      <td>0:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>4.70</td>\n",
              "      <td>4.71</td>\n",
              "      <td>4.74e-01</td>\n",
              "      <td>0:00:23</td>\n",
              "      <td>0:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>4.48</td>\n",
              "      <td>4.51</td>\n",
              "      <td>5.92e-01</td>\n",
              "      <td>0:00:23</td>\n",
              "      <td>0:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>4.28</td>\n",
              "      <td>4.32</td>\n",
              "      <td>6.37e-01</td>\n",
              "      <td>0:00:23</td>\n",
              "      <td>0:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>4.09</td>\n",
              "      <td>4.16</td>\n",
              "      <td>6.77e-01</td>\n",
              "      <td>0:00:23</td>\n",
              "      <td>0:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>3.91</td>\n",
              "      <td>3.99</td>\n",
              "      <td>7.26e-01</td>\n",
              "      <td>0:00:23</td>\n",
              "      <td>0:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>3.75</td>\n",
              "      <td>3.84</td>\n",
              "      <td>7.81e-01</td>\n",
              "      <td>0:00:23</td>\n",
              "      <td>0:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>3.60</td>\n",
              "      <td>3.71</td>\n",
              "      <td>7.86e-01</td>\n",
              "      <td>0:00:23</td>\n",
              "      <td>0:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>3.47</td>\n",
              "      <td>3.60</td>\n",
              "      <td>8.08e-01</td>\n",
              "      <td>0:00:23</td>\n",
              "      <td>0:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>3.34</td>\n",
              "      <td>3.49</td>\n",
              "      <td>8.39e-01</td>\n",
              "      <td>0:00:23</td>\n",
              "      <td>0:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>3.23</td>\n",
              "      <td>3.38</td>\n",
              "      <td>8.48e-01</td>\n",
              "      <td>0:00:23</td>\n",
              "      <td>0:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>3.13</td>\n",
              "      <td>3.29</td>\n",
              "      <td>8.53e-01</td>\n",
              "      <td>0:00:23</td>\n",
              "      <td>0:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>3.04</td>\n",
              "      <td>3.22</td>\n",
              "      <td>8.62e-01</td>\n",
              "      <td>0:00:23</td>\n",
              "      <td>0:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>2.95</td>\n",
              "      <td>3.13</td>\n",
              "      <td>8.66e-01</td>\n",
              "      <td>0:00:23</td>\n",
              "      <td>0:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>2.88</td>\n",
              "      <td>3.06</td>\n",
              "      <td>8.79e-01</td>\n",
              "      <td>0:00:23</td>\n",
              "      <td>0:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2.82</td>\n",
              "      <td>3.01</td>\n",
              "      <td>8.71e-01</td>\n",
              "      <td>0:00:23</td>\n",
              "      <td>0:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2.78</td>\n",
              "      <td>2.97</td>\n",
              "      <td>8.79e-01</td>\n",
              "      <td>0:00:23</td>\n",
              "      <td>0:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2.74</td>\n",
              "      <td>2.94</td>\n",
              "      <td>8.88e-01</td>\n",
              "      <td>0:00:23</td>\n",
              "      <td>0:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2.70</td>\n",
              "      <td>2.91</td>\n",
              "      <td>8.93e-01</td>\n",
              "      <td>0:00:23</td>\n",
              "      <td>0:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>2.69</td>\n",
              "      <td>2.90</td>\n",
              "      <td>8.88e-01</td>\n",
              "      <td>0:00:23</td>\n",
              "      <td>0:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>2.67</td>\n",
              "      <td>2.89</td>\n",
              "      <td>8.93e-01</td>\n",
              "      <td>0:00:23</td>\n",
              "      <td>0:00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3ae90bd5-04ed-4156-8a50-43061d664900')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3ae90bd5-04ed-4156-8a50-43061d664900 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3ae90bd5-04ed-4156-8a50-43061d664900');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68xreA9JAmG5",
        "outputId": "1f5ce6f1-8396-456d-f8ef-2c933e4e5be4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2]) #, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkyubuJSOzg3"
      },
      "source": [
        "# 6. Test Set Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16lctEOyNFik"
      },
      "source": [
        "## 6.2. Evaluate on Test Set\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hba10sXR7Xi6",
        "outputId": "dcc12f62-1156-4d28-c7da-fb97c8296dda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in train_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  # b_input_ids, b_input_mask, b_labels = batch\n",
        "  b_input_ids, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      # outputs = model(b_input_ids, token_type_ids=None, \n",
        "      #                 attention_mask=b_input_mask)\n",
        "      outputs = model(b_input_ids, token_type_ids=None)\n",
        "\n",
        "  logits = outputs[0]\n",
        "  \n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('Done with test set evaluation.')"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done with test set evaluation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test set accuracy"
      ],
      "metadata": {
        "id": "M87W6tmcyOwr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_flat = []\n",
        "true_flat = []\n",
        "for pred_b, true_b in zip(predictions, true_labels):\n",
        "\n",
        "  for pred in pred_b:\n",
        "    pred = list(pred)\n",
        "    max_value = max(pred)\n",
        "    max_index = pred.index(max_value)\n",
        "\n",
        "    predictions_flat.append(max_index)\n",
        "\n",
        "  true_flat += list(true_b)"
      ],
      "metadata": {
        "id": "5QG0d7dYsw2R"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true = 0\n",
        "false = 0\n",
        "for tru, pred in zip(true_flat, predictions_flat):\n",
        "    if tru == pred:\n",
        "      true += 1\n",
        "    else:\n",
        "      false += 1 \n",
        "\n",
        "print(f\"Accuracy across all classes: {'{:.3f}'.format(true / (false + true))}\" )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_7H6Wpiv9OY",
        "outputId": "6ff10000-6317-4704-8b69-e2e6a70ea781"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy across all classes: 0.961\n"
          ]
        }
      ]
    }
  ]
}